{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Frm06ZPq8noY"
   },
   "source": [
    "# CMU auto-graded notebook\n",
    "\n",
    "Before you turn these assignments in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE`, `<FILL IN>`, or \"YOUR ANSWER HERE.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfii2P5r8nob"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1tnkgBl8nob"
   },
   "source": [
    "# CMU Machine Learning with Large Datasets\n",
    "\n",
    "## Homework 1 - Coding 2: Streaming Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GxsV3uA48noc",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:31.295629Z",
     "start_time": "2025-01-25T23:52:31.293096Z"
    }
   },
   "source": [
    "# Who did you collaborate with on this assignment?\n",
    "# if no one, collaborators should contain an empty string,\n",
    "# else list your collaborators below\n",
    "\n",
    "collaborators = [\"\"]\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p5ux33if8noc",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:31.301476Z",
     "start_time": "2025-01-25T23:52:31.299008Z"
    }
   },
   "source": [
    "try:\n",
    "    collaborators\n",
    "except:\n",
    "    raise AssertionError(\"you did not list your collaborators, if any\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLWy2qaP8nod"
   },
   "source": [
    "### (1a) Environment Setup\n",
    "\n",
    "Run the following cell to establish the runtime environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dq_Yf3an8nod",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:31.936557Z",
     "start_time": "2025-01-25T23:52:31.310555Z"
    }
   },
   "source": [
    "# Ignore this cell if the environment already has the packages\n",
    "\n",
    "%pip install nose numpy"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nose in /Users/leesunny/S25_10605/.venv/lib/python3.9/site-packages (1.3.7)\r\n",
      "Requirement already satisfied: numpy in /Users/leesunny/S25_10605/.venv/lib/python3.9/site-packages (2.0.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yl9JFmyO8nod",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.019071Z",
     "start_time": "2025-01-25T23:52:31.941821Z"
    }
   },
   "source": [
    "# imports that will be used in the notebook -- shouldn't need to import any other libraries\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from nose.tools import assert_equal"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV7vgXw08noe"
   },
   "source": [
    "### (1b) Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k03fgbvg8noe"
   },
   "source": [
    "We use the Reuters Corpus (RCV1), which is a set of news stories split into a hierarchy of categories. There are three file sets. The two data sets with \"small\" in the name contain smaller subsamples of the full data set. They are provided for debugging and local tests. The final classification task should use the \"full\" one. Each data set is split into a train and test set, as indicated by the file suffix:\n",
    "\n",
    "- RCV1.full_train.txt\n",
    "- RCV1.full_test.txt\n",
    "- RCV1.small_train.txt\n",
    "- RCV1.small_test.txt\n",
    "- RCV1.very_small_train.txt\n",
    "- RCV1.very_small_test.txt\n",
    "\n",
    "Download the data using the link provided in the handout, and fill in the corresponding variables with their file paths in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yyo_7ru08noe",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.025314Z",
     "start_time": "2025-01-25T23:52:32.023566Z"
    }
   },
   "source": [
    "# TODO: Replace <FILL IN> with appropriate file paths\n",
    "FULL_TRAIN = \"/Users/leesunny/S25_10605/S25_HW1-hw1/10605_S25_HW1_RCV1/RCV1.full_train.txt\"\n",
    "FULL_TEST = \"/Users/leesunny/S25_10605/S25_HW1-hw1/10605_S25_HW1_RCV1/RCV1.full_test.txt\"\n",
    "SMALL_TRAIN = \"/Users/leesunny/S25_10605/S25_HW1-hw1/10605_S25_HW1_RCV1/RCV1.small_train.txt\"\n",
    "SMALL_TEST = \"/Users/leesunny/S25_10605/S25_HW1-hw1/10605_S25_HW1_RCV1/RCV1.small_test.txt\"\n",
    "VERY_SMALL_TRAIN = \"/Users/leesunny/S25_10605/S25_HW1-hw1/10605_S25_HW1_RCV1/RCV1.very_small_train.txt\"\n",
    "VERY_SMALL_TEST = \"/Users/leesunny/S25_10605/S25_HW1-hw1/10605_S25_HW1_RCV1/RCV1.very_small_test.txt\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZbUFSjw8noe"
   },
   "source": [
    "There are multiple class labels per document, meaning that there is more than one correct answer to the question \"What kind of news article is this?\"\n",
    "\n",
    "For this assignment, we will ignore all class labels except for those ending in CAT and just be classifying into the top-level nodes of the hierarchy:\n",
    "\n",
    "- CCAT: Corporate/Industrial\n",
    "- ECAT: Economics\n",
    "- GCAT: Government/Social\n",
    "- MCAT: Markets\n",
    "\n",
    "DO NOT change the following cell and just run it to set up the CAT labels\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7qKcB8ML8nof",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.030870Z",
     "start_time": "2025-01-25T23:52:32.029382Z"
    }
   },
   "source": [
    "CAT_LABELS = ['CCAT', 'ECAT', 'GCAT', 'MCAT']"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scv5Rgiz8nof"
   },
   "source": [
    "The data format is one document per line, with the class label(s) first (comma separated), a tab character, and then the document text.\n",
    "\n",
    "Run the following cell to take a glance at the first document of the small training data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F0CVLqKZ8nof",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.036932Z",
     "start_time": "2025-01-25T23:52:32.034796Z"
    }
   },
   "source": [
    "with open(SMALL_TRAIN, 'r') as f:\n",
    "    print(f.readline())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C13,C21,CCAT\t The German government on Thursday awarded the first round of licences for basic public telephone services, opening the door for full competition to monopoly Deutsche Telekom. Kicking off the final stage of preparations ahead of liberalisation of European telecoms on January 1, 1998, Germany awarded licences for basic phone services to Vebacom GmbH, Britain's Colt Telecom Plc and NetCologne, a local operator.   The so-called &quot;class four&quot; licences cover basic voice telephone services for the public. That is the only service still under monopoly protection in Germany, where the telecoms market is expected to be worth more than 100 billion marks by the year 2000. In addition to the class 4 licences, the government awarded &quot;class 3&quot; licences to DBKom GmbH, the joint venture of a Mannesmann-led group and the German railway Deutsche Bahn AG, as well as to local operator VEW Telnet. Under a law passed this year, the class 3 licence allow owners of telecoms networks to lease capacity on these networks to other carriers or to companies for setting up internal communications networks. Previously, only Deutsche Telekom was allowed to do this. DBKom's licence is for national coverage, while the licence for VEW Telnet covers the northern cities of Muenster, Detmold and Arnsberg. Vebacom, the joint venture of energy group Veba AG and U.K.-based Cable and Wireless, welcomed the decision but said there were still questions about the conditions placed on licence holders. &quot;As the first new competitor (to Telekom), we received our network licence in October. Now we have our public phone licence and therefore all of the legal conditions to become a comprehensive carrier,&quot; Veba chairman Ulf Bohla told Reuters. Vebacom's licence is for national basic telephone services, while NetCologne's licence covers the greater Cologne region, and Colt's is for the cities of Frankfurt, Hamburg, Berlin, Potsdam and Munich, the Post and Telecommunications Ministry said. Post and Telecommunications Minister Wolfgang Boetsch told reporters late on Tuesday there were currently 11 applications for licences to provide public telephone services pending. Seven of the applications are for a national telephone service and the rest are for regional service. Next year will see some of the world's largest players on the telecommunications market and their German partners, several of Germany's biggest enterprises, make their final moves to compete against monopoly Telekom beginning in 1998. A dispute over the costs of the licences has been simmering for months. The government, seeking to plug yawning budget deficits, hopes to gain around 1.6 billion marks in one-off fees for new telecommunications licences. At around 40 million marks for a nationwide licence, industry representatives have called this an &quot;investment tax&quot; that would become just another excuse not to invest in Germany. &quot;We must clarify the licence conditions. The important question of the licence fees is still open,&quot; Bohla said. -- William Boston, Bonn Newsroom, 49 228 26097150\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECKKg-Q88nof"
   },
   "source": [
    "### (1c) Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzF7Uocx8nof"
   },
   "source": [
    "To count the words, we need to tokenize the document text. In real-world practice, this may involve multiple steps, such as removing stop words and converting text to lowercase, which you learned in HW1: Entity Resolution. For this Naive Bayes part, we simplify the process by splitting only on words.\n",
    "\n",
    "Run the following cell to define the `tokenization(doc)` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fp01Z4-K8nof",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.046864Z",
     "start_time": "2025-01-25T23:52:32.045057Z"
    }
   },
   "source": [
    "# DO NOT change this function\n",
    "def tokenizeDoc(doc: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Convert input document text into tokenization features\n",
    "    Args:\n",
    "        doc: document text\n",
    "    Returns:\n",
    "        list: a list of tokens\n",
    "    \"\"\"\n",
    "    return re.findall('\\\\w+', doc)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5s0UoRA8nof"
   },
   "source": [
    "As the handout instructs, streaming Naive Bayes loads one-line document at a time, use that document to update the classifier statistics, and then discard the document. After loading a line, we need a function to parse the line for classifier training.\n",
    "\n",
    "Implement `parseDatafileLine(datafileLine)` that takes a line (labels + document text) and return a list of labels and a list of tokens. You need to use the `tokenizeDoc(doc)` function defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4kuQlvTC8nof",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.052963Z",
     "start_time": "2025-01-25T23:52:32.051029Z"
    }
   },
   "source": [
    "def parseDatafileLine(datafileLine: str):\n",
    "    \"\"\"\n",
    "    Parse a line of the data file to separate labels and document tokens\n",
    "    Args:\n",
    "        datafileLine: input string that is a line from the data file\n",
    "    Returns:\n",
    "        labels (list), tokens (list)\n",
    "    \"\"\"\n",
    "    # TODO: YOUR CODE HERE\n",
    "    # split the line into the labels and the document text using a tab\n",
    "    parts = datafileLine.strip().split('\\t')\n",
    "    # the first part of the split is the labels, which are space-separated\n",
    "    labels = parts[0].split(',')\n",
    "    # the rest fo the line is the doc text\n",
    "    document_text = parts[1] if len(parts)>1 else ''\n",
    "    # tokenize the doc text\n",
    "    tokens = tokenizeDoc(document_text)\n",
    "\n",
    "    return labels, tokens\n",
    "    # raise NotImplementedError()"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2FFa2bdI8nof",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.059010Z",
     "start_time": "2025-01-25T23:52:32.056818Z"
    }
   },
   "source": [
    "\"\"\"Test parseDatafileLine(datafileLine)\"\"\"\n",
    "\n",
    "line_sample1 = \"C15,C151,CCAT\\tMcDonald's Corp said Thursday it raised its quarterly dividend 10 percent, to $0.0825 a share from $0.075.\"\n",
    "line_sample2 = \"C15,C151,CCAT\\tSix months to Sept 30, 1996       (in million rupees unless stated)\"\n",
    "\n",
    "assert_equal(parseDatafileLine(line_sample1),\n",
    "             (['C15', 'C151', 'CCAT'],\n",
    "              ['McDonald', 's', 'Corp', 'said', 'Thursday', 'it', 'raised', 'its',\n",
    "               'quarterly', 'dividend', '10', 'percent', 'to', '0', '0825', 'a',\n",
    "               'share', 'from', '0', '075']))\n",
    "\n",
    "assert_equal(parseDatafileLine(line_sample2),\n",
    "             (['C15', 'C151', 'CCAT'],\n",
    "              ['Six', 'months', 'to', 'Sept', '30', '1996', 'in', 'million',\n",
    "               'rupees', 'unless', 'stated']))"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjYi1Fca8nog"
   },
   "source": [
    "### 1(d) Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_zH3_lG8nog"
   },
   "source": [
    "Now, we are good for training. We will use a dictionary as the model to store the count statistics.\n",
    "\n",
    "As the handout instructs, the model contains five parts:\n",
    "\n",
    "- `y`: $(Y=y)$ for each label y the number of training instances of that class\n",
    "- `ys`: $(Y=*)$ here $*$ means anything, so this is just the total number of training instances\n",
    "- `y_w`: $(Y=y,W=w)$ number of times token w appears in a document with label y\n",
    "- `y_ws`: $(Y=y,W=*)$ total number of tokens for documents with label y\n",
    "- `vocabulary`: track the vocabulary for Laplace smoothing\n",
    "\n",
    "Recall that Laplace smoothing formula is\n",
    "\n",
    "$$p(W=w_i|Y=y)=\\frac{count(Y=y,W=w_i) + \\alpha}{count(Y=y,W=*)+ \\alpha|V|}$$\n",
    "where $|V|$ is the vocabulary.\n",
    "\n",
    "Implement `nbmodel()` by figuring out the proper variable types for each part and filling in the blank below.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oMc-kFwL8nog",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.064514Z",
     "start_time": "2025-01-25T23:52:32.062938Z"
    }
   },
   "source": [
    "def nbmodel() -> dict:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        dict storing the required five parts\n",
    "    \"\"\"\n",
    "    # TODO: Replace <FILL IN> with appropriate code\n",
    "    return {\n",
    "        'y': {},\n",
    "        'ys': 0,\n",
    "        'y_w': {},\n",
    "        'y_ws': {},\n",
    "        'vocabulary': set()\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BUeeEaf8nog"
   },
   "source": [
    "Implement `trainNB(trainfile, model)` that loads one document at a time and uses that document to update the required statistics for the Naive Bayes classifier.\n",
    "\n",
    "Hint:\n",
    "\n",
    "1. We only use those lables ending in CAT, which defined in `CAT_LABELS` earlier. Therefore, you need to figure out a way to skip other labels.\n",
    "2. There are some documents with more than one CAT label. Treat those documents as multiple data instances (that is, add to the counters for\n",
    "   all labels ending in CAT). For instance, if one line contains CCAT and ECAT, use the same document text twice.\n",
    "3. It is not necessary to return the model here if you use proper types. Think about Python's mutable vs immutable types.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RnuvT2vN8nog",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.070750Z",
     "start_time": "2025-01-25T23:52:32.068158Z"
    }
   },
   "source": [
    "def trainNB(trainfile: str, model: dict):\n",
    "    \"\"\"\n",
    "    Update the model in a streaming fashion.\n",
    "    Args:\n",
    "        trainfile: file path of the training data\n",
    "        model: dict of the Naive Bayes classifier model\n",
    "    \"\"\"\n",
    "\n",
    "    with open(trainfile, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            labels, tokens = parseDatafileLine(line)\n",
    "\n",
    "            # Filter only labels ending in \"CAT\"\n",
    "            relevant_labels = [label for label in labels if label.endswith(\"CAT\")]\n",
    "\n",
    "            # Update the model for each relevant label\n",
    "            for label in relevant_labels:\n",
    "                # Initialize structures for new labels\n",
    "                if label not in model['y_w']:\n",
    "                    model['y_w'][label] = {}\n",
    "\n",
    "                # Update class count and total document count\n",
    "                model['y'][label] = model['y'].get(label, 0) + 1\n",
    "                model['ys'] += 1\n",
    "\n",
    "                # Update token counts and vocabulary\n",
    "                for token in tokens:\n",
    "                    model['y_w'][label][token] = model['y_w'][label].get(token, 0) + 1\n",
    "                    model['y_ws'][label] = model['y_ws'].get(label, 0) + 1\n",
    "                    model['vocabulary'].add(token)\n",
    "\n",
    "            # TODO: YOUR CODE HERE\n",
    "            # raise NotImplementedError()"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJwHoz4m8nog"
   },
   "source": [
    "### 1(e) Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N_CFBED8nog"
   },
   "source": [
    "For each line of documents, your classification code should get the best class $y$ and its log probabilities:\n",
    "\n",
    "$$ln(p(Y=y))+\\sum_{w_i} ln(p(W=w_i|Y=y))$$\n",
    "\n",
    "Notice that we use the natural logarithm here.\n",
    "\n",
    "Implement `testNB(testfile, model)` that uses the trained model to classify the test data and return a list of best classes, a list of max log probabilities (**rounding it to 4 decimal places**), and overall accuracy (**rounding it to 4 decimal places**). Please explicitly return in this specified order.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_gWRRfMu8nog",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.077305Z",
     "start_time": "2025-01-25T23:52:32.074479Z"
    }
   },
   "source": [
    "def testNB(testfile, model):\n",
    "    \"\"\"\n",
    "    Implement Naive Bayes classification\n",
    "    Args:\n",
    "        testfile: file path of the test data\n",
    "        model: dict of the Naive Bayes classifier model\n",
    "    Returns:\n",
    "        best_classes, log_probabilities, accuracy\n",
    "    \"\"\"\n",
    "    best_classes = []\n",
    "    log_probabilities = []\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Get the size of the vocabulary for smoothing\n",
    "    vocab_size = len(model['vocabulary'])\n",
    "\n",
    "    with open(testfile, encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f.readlines():\n",
    "            labels, tokens = parseDatafileLine(line)\n",
    "\n",
    "            # initialize the dic to store log prob for each class\n",
    "            class_log_probs = {}\n",
    "\n",
    "            # calculate log prob for each class\n",
    "            for label in model['y']:\n",
    "                # log prior:\n",
    "                log_prior = math.log((model['y'][label]) / sum(model['y'].values()))\n",
    "\n",
    "                # log likelihood:\n",
    "                log_likelihood = 0\n",
    "                for token in tokens:\n",
    "                    token_count = model['y_w'][label].get(token, 0)\n",
    "                    token_prob = (token_count + 1) / (model['y_ws'][label] + vocab_size)\n",
    "                    log_likelihood += math.log(token_prob)\n",
    "\n",
    "                # total log prob for this class\n",
    "                class_log_probs[label] = log_prior + log_likelihood\n",
    "\n",
    "            # find the best class with highiest prob\n",
    "            best_class = max(class_log_probs, key=class_log_probs.get)\n",
    "            best_log_prob = class_log_probs[best_class]\n",
    "\n",
    "            best_classes.append(best_class)\n",
    "            log_probabilities.append(round(best_log_prob, 4))\n",
    "\n",
    "            # check if the best class is among the true labels\n",
    "            if best_class in labels:\n",
    "                correct_predictions += 1\n",
    "\n",
    "            total_samples += 1\n",
    "\n",
    "    accuracy = round(correct_predictions / total_samples, 4)\n",
    "            # raise NotImplementedError()\n",
    "    return best_classes, log_probabilities, accuracy"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XodcTc5w8nog",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.092016Z",
     "start_time": "2025-01-25T23:52:32.080858Z"
    }
   },
   "source": [
    "\"\"\"DO NOT change this this cell and just run it to use the very small dataset to test your implementations\"\"\"\n",
    "\n",
    "very_small_model = nbmodel()\n",
    "trainNB(VERY_SMALL_TRAIN, very_small_model)\n",
    "best_classes, log_probabilities, accuracy = testNB(VERY_SMALL_TEST, very_small_model)\n",
    "\n",
    "assert_equal(best_classes,\n",
    "             ['MCAT', 'ECAT', 'CCAT', 'ECAT', 'CCAT', 'CCAT', 'ECAT', 'CCAT'])\n",
    "assert_equal(log_probabilities,\n",
    "             [-9893.7804, -3912.8180, -1121.5992, -1610.1660,\n",
    "              -701.3466, -1453.3430, -2218.3302, -2285.0698])\n",
    "assert_equal(accuracy, 0.8750)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8Stku3d8nog"
   },
   "source": [
    "### 1(f) Full Classification and Deliverable\n",
    "\n",
    "We are almost there! Let's wrap up this assignment.\n",
    "\n",
    "Implement your training and test functions on the full dataset to get the full classification results. Please note that you need to define a new model different from the `very_small_model` we have already tested.\n",
    "\n",
    "Write the full classification results to a file `full_result.txt` (please explicitly use this name). The output format should have one test result per line, and each line should have the format:\n",
    "\n",
    "$$\\text{[Label1, Label2, ...]<tab>Best class<tab>Log prob}$$\n",
    "\n",
    "where **[Label1, Label2, ...]** are the true labels of the test instance, **Best class** is the class with the maximum log probability, and the last field is the log probability.\n",
    "\n",
    "The last line of the file should include the accuracy.\n",
    "\n",
    "Use the following cell to write your code.\n",
    "\n",
    "Submit both this notebook and `full_result.txt` to Gradescope.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JzdWLHm58nog",
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.098850Z",
     "start_time": "2025-01-25T23:52:32.096605Z"
    }
   },
   "source": [
    "# * Here is an expected output of very_small_test dataset for your reference\n",
    "# * You need to write one using the FULL dataset\n",
    "\n",
    "'''\n",
    "['C24', 'CCAT', 'M14', 'MCAT']\\tMCAT\\t-9893.7804\n",
    "['E51', 'E512', 'ECAT', 'GCAT', 'GDIP']\\tECAT\\t-3912.8180\n",
    "['C15', 'C152', 'C18', 'C181', 'CCAT']\\tCCAT\\t-1121.5992\n",
    "['GCAT']\\tECAT\\t-1610.1660\n",
    "['C13', 'CCAT', 'GCAT', 'GHEA']\\tCCAT\\t-701.3466\n",
    "['C13', 'CCAT', 'M11', 'MCAT']\\tCCAT\\t-1453.3430\n",
    "['C11', 'C13', 'CCAT', 'E12', 'ECAT', 'M13', 'M132', 'MCAT']\\tECAT\\t-2218.3302\n",
    "['C31', 'CCAT']\\tCCAT\\t-2285.0698\n",
    "Accuracy: 7/8=0.8750\n",
    "'''"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n['C24', 'CCAT', 'M14', 'MCAT']\\tMCAT\\t-9893.7804\\n['E51', 'E512', 'ECAT', 'GCAT', 'GDIP']\\tECAT\\t-3912.8180\\n['C15', 'C152', 'C18', 'C181', 'CCAT']\\tCCAT\\t-1121.5992\\n['GCAT']\\tECAT\\t-1610.1660\\n['C13', 'CCAT', 'GCAT', 'GHEA']\\tCCAT\\t-701.3466\\n['C13', 'CCAT', 'M11', 'MCAT']\\tCCAT\\t-1453.3430\\n['C11', 'C13', 'CCAT', 'E12', 'ECAT', 'M13', 'M132', 'MCAT']\\tECAT\\t-2218.3302\\n['C31', 'CCAT']\\tCCAT\\t-2285.0698\\nAccuracy: 7/8=0.8750\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T23:52:32.107690Z",
     "start_time": "2025-01-25T23:52:32.104953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def full_classification(train_file, test_file):\n",
    "    \"\"\"\n",
    "    Train and test the Naive Bayes classifier on the full dataset and write results to a file.\n",
    "\n",
    "    Args:\n",
    "        train_file: File path to the training data.\n",
    "        test_file: File path to the test data.\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize the Naive Bayes model\n",
    "    full_model = nbmodel()\n",
    "\n",
    "    # Step 2: Train the model on the full training dataset\n",
    "    trainNB(train_file, full_model)\n",
    "\n",
    "    # Step 3: Test the model on the full test dataset\n",
    "    best_classes, log_probabilities, accuracy = testNB(test_file, full_model)\n",
    "\n",
    "    # Step 4: Write the classification results to 'full_result.txt'\n",
    "    with open(\"full_result.txt\", \"w\") as result_file:\n",
    "        total_samples = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        # Read the test file and process each line\n",
    "        with open(test_file, \"r\") as test_data:\n",
    "            for line, best_class, log_prob in zip(test_data.readlines(), best_classes, log_probabilities):\n",
    "                # Parse the true labels and tokens from the test file\n",
    "                labels, _ = parseDatafileLine(line)\n",
    "                total_samples += 1\n",
    "\n",
    "                # Check if the prediction is correct\n",
    "                if best_class in labels:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "                # Write the result for this instance in the specified format\n",
    "                result_file.write(f\"[{', '.join(labels)}]\\t{best_class}\\t{log_prob:.4f}\\n\")\n",
    "\n",
    "        # Step 5: Write the accuracy to the last line of the file\n",
    "        accuracy_fraction = f\"{correct_predictions}/{total_samples}={accuracy:.4f}\"\n",
    "        result_file.write(f\"Accuracy: {accuracy_fraction}\\n\")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T23:54:02.103800Z",
     "start_time": "2025-01-25T23:52:32.112994Z"
    }
   },
   "cell_type": "code",
   "source": "full_classification(FULL_TRAIN, FULL_TEST)",
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
