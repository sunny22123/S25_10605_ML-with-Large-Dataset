{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunny22123/S25_10605_ML-with-Large-Dataset/blob/main/final_project_CNN_pruning_students_pytorch_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6_xSmL5Ud-L"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8-4wiwDUd-N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "mMW4Q-RtJxiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5esWnmZ1Ud-O"
      },
      "outputs": [],
      "source": [
        "# untar\n",
        "!ls\n",
        "!tar -xvzf dataset.tar.gz\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG6sBNS2Ud-P"
      },
      "outputs": [],
      "source": [
        "train_images = torch.tensor(train_images, dtype=torch.float32)\n",
        "val_images = torch.tensor(val_images, dtype=torch.float32)\n",
        "\n",
        "train_images = train_images.permute(0, 3, 1, 2)\n",
        "val_images = val_images.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zvu3f3yUd-P"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(train_images,\n",
        "                              torch.tensor(train_labels.squeeze(), dtype=torch.long))\n",
        "val_dataset = TensorDataset(val_images,\n",
        "                            torch.tensor(val_labels.squeeze(), dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BBS787DUd-Q"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mzgqu2UbUd-Q"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # First block: Conv -> ReLU -> Conv -> ReLU -> MaxPool -> Dropout\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=0, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            # Second block: Conv -> ReLU -> Conv -> ReLU -> MaxPool -> Dropout\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=0, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            # Flatten layer\n",
        "            nn.Flatten(),\n",
        "\n",
        "            # Fully connected block: Dense -> ReLU -> Dropout -> Dense -> Softmax\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 5),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYW_6NgEUd-Q"
      },
      "outputs": [],
      "source": [
        "model = ConvNet()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "summary(model, input_size=(3, 25, 25))"
      ],
      "metadata": {
        "id": "z_toyD_1VQsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Progress bar for the training loop\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for inputs, labels in train_loader_tqdm:\n",
        "        optimizer.zero_grad()  # Zero the parameter gradients\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Update tqdm description with current loss and accuracy\n",
        "        train_loader_tqdm.set_postfix(loss=running_loss / total, accuracy=100 * correct / total)\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    return train_loss, train_accuracy"
      ],
      "metadata": {
        "id": "wALYsoeSMN-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Progress bar for the validation loop\n",
        "    val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations for validation\n",
        "        for inputs, labels in val_loader_tqdm:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Track loss and accuracy\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Update tqdm description with current validation loss and accuracy\n",
        "            val_loader_tqdm.set_postfix(loss=val_loss / total, accuracy=100 * correct / total)\n",
        "\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "NnYV0D4VMPES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Training\n",
        "    train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
        "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "60-Jum5EMTFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'my_model_weights_1.pt', _use_new_zipfile_serialization=False)"
      ],
      "metadata": {
        "id": "-rCvWKq2S5mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os4z3KodUd-S"
      },
      "source": [
        "### Zeroing weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88KDlQ6VUd-S"
      },
      "source": [
        "Example on how to set weights to zero. You should determine which weights to set to zero using the approaches you defined in the form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byZEZWEmUd-S"
      },
      "outputs": [],
      "source": [
        "# Set weights that are less than 0.5 to zero\n",
        "with torch.no_grad():  # disable gradient tracking for efficiency\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"weight\" in name:  # only apply to weights, skip biases\n",
        "            param[param < 0.9] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBGJxD87Ud-S"
      },
      "outputs": [],
      "source": [
        "val_loss, val_accuracy = validate(model, val_loader, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy"
      ],
      "metadata": {
        "id": "tc35gGwCNxWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6T-IJ_gUd-S"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'my_model_weights_2.pt', _use_new_zipfile_serialization=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}